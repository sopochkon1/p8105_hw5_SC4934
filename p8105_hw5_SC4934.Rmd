---
title: "p8105_hw5_SC4934"
author: "Sophia Chkonia"
date: "2022-11-15"
output: html_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)
library(rvest)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


### Problem 0 


```{r results = "hide", message = FALSE, load_libraries}
library(tidyverse)
library(ggplot2)

```

## Problem 1

```{r results = "hide", message = FALSE}
full_df = 
  tibble(
    files = list.files("data/zip_data/"),
    path = str_c("data/zip_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

### To tidy the dataframe: 

```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

### Spaghetti plot:

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

The path shows bigger change in outcome (linear increase) in the experimental group than the control group, where the outcome stays relatively the same through the weeks. The plot also shows high within-subject correlation, meaning that the subjects that are above average at the beginning of the observation period are above average at the end of the study period, and vice versa. 


## Problem 2 
```{r results = "hide", message = FALSE}
homicide = 
read_csv(
  "data/homicide-data.csv"
) %>% 
  janitor::clean_names() %>% 
  mutate(
    state = case_when(city == "Tulsa" ~ "OK", TRUE ~ as.character(state)),
    city_state = str_c(city, ", ", state)) %>% 
  group_by(city_state) %>% 
  summarise(
    homicide = n(),
    unsolved = sum(disposition == "Closed without arrest" | disposition == "Open/No arrest")
  ) 
 
```

The `homicide` dataset includes information on homicide vicitms in 50 US cities. There are 
`r ncol(homicide)` columns and `r nrow(homicide)` rows in the dataset, with variables such as 
`victim_last`, `victim_first`, `city`, `state`, `lat`, `lon`, etc. 

There appeared to be a mistake in the data where Tulsa, OK was input as Tulsa, AL, making the number of cities 51 instead of 50. As part of tidying the dataset I changed the state variable 
from AL to OK, before combining `city` and `state` into `city_state`, which corrected the error. 

### Prop.test Baltimore 

```{r}
Baltimore = 
  homicide %>% 
  filter(
    city_state == "Baltimore, MD"
  )
  
proptest = 
  prop.test(
    x = Baltimore %>% pull(unsolved), 
    n = Baltimore %>% pull(homicide),
    alternative = c("two.sided"),
    conf.level = 0.95, correct = TRUE
  ) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high) 
  

```


### For each city 

```{r}

each_city = 
  homicide %>% mutate(
   newcol = purrr::map2(unsolved, homicide, prop.test),
   estimate = map_dbl(newcol, ~ .x[["estimate"]]),
   CI = map(newcol, ~as.numeric(.x[["conf.int"]]))
  ) %>% 
  separate(CI, into = c("conf.low", "conf.high"), sep = ", ") %>% 
  mutate(
    conf.low = str_sub(conf.low, 3, 11),
    conf.high = str_sub(conf.high, 1, 9),
    ) %>% 
  select(
    city_state, estimate, conf.low, conf.high
  ) 


```

### Plot

```{r}
each_city %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymin = as.numeric(conf.low), ymax = as.numeric(conf.high))) +
  labs(
    x = "City, State",
    y = "Estimate (CI)",
    title = "Proportion per City"
  ) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "none")
```


## Problem 3

```{r}
set.seed(1)

sim_t_test = function(mu){
sample = rnorm(30, mu, sd = 5)
test_results = t.test(sample) %>% 
  broom::tidy()
}


# 5000 iterations when mu = 0
sim_results_df_0 = 
  expand_grid(
    mu = 0,
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = map(mu, sim_t_test)
  ) %>% 
  unnest(estimate_df)

# Repeat for mu = 1 : 6

sim_results_df_1to6 = 
  expand_grid(
    mu = c(1:6),
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = map(mu, sim_t_test)
  ) %>% 
  unnest(estimate_df)

# Final repeat for mu = 0 : 6
sim_results_df = 
  expand_grid(
    mu = c(0:6),
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = map(mu, sim_t_test)
  ) %>% 
  unnest(estimate_df)
```

### Plot

```{r}
Power_vs_mu = 
  sim_results_df %>% 
  mutate(
    status = ifelse(p.value < 0.05, TRUE, FALSE)
  ) %>% 
  group_by(mu) %>% 
  summarise(power = sum(status)/5000) %>% 
  ggplot(aes(x = mu, y = power)) +
  geom_point(aes(color = mu)) +
  geom_line(alpha = .5) +
  labs(
    title = "Power vs True Mean",
    x = "True Mean",
    y = "Power"
  )
```

As observed in the above plot, the Power of the test increases as the true mean (mu) increases, therefore, there is a positive association between the effect size and power.  

### Second Plot

```{r}
all = 
  sim_results_df %>% 
  group_by(mu) %>% 
  summarise(all_mean = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = all_mean)) +
  geom_point(alpha = 0.5) +
  geom_line()+
  labs(
    title = "Average of μ^ vs true value ",
    x = "True Value of μ",
    y = "Average estimate of μ^"
  )


reject = 
  sim_results_df %>%
  mutate(
    status = ifelse(p.value < 0.05, TRUE, FALSE)
  ) %>% 
  group_by(mu) %>% 
  filter(status == TRUE) %>% 
  summarise(reject_mean = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = reject_mean)) +
  geom_point(alpha = 0.5) +
  geom_line() +
  labs(
    title = "Average of μ^ in rejected null vs true value ",
    x = "True Value of μ",
    y = "Average estimate of μ^"
  )

# Plots: 
all
reject

```

The sample average of μ̂  across tests for which the null is rejected does not match the  true value of μ, especially when there is low power. This could be because if you only look at results that reject the null, so only significant results, those results will not match the true value of  μ. This is especially true with low power or low sample size.   







